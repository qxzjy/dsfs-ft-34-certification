{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a025ea1",
   "metadata": {},
   "source": [
    "# Target : summarizing the reviews on a given anime\n",
    "\n",
    "Objective : only have a few sentences summarizing an anime's strongpoints and drawbacks instead of having to browse through many reviews, to get a general impression that is representative of the whole community's feelings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232e6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antog96/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import torch\n",
    "import transformers\n",
    "import re\n",
    "import string\n",
    "import tiktoken\n",
    "import requests\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8494eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2272107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29aea9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f460660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe_summarization = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",)\n",
    "\n",
    "pipe_sentiment = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a571db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset import\n",
    "df_reviews = pd.read_csv(\"https://anime-recommendation-engine.s3.eu-west-3.amazonaws.com/data/reviews_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267e5fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>profile</th>\n",
       "      <th>anime_uid</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>scores</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255938</td>\n",
       "      <td>DesolatePsyche</td>\n",
       "      <td>34096</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>8</td>\n",
       "      <td>{'Overall': '8', 'Story': '8', 'Animation': '8...</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=255938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259117</td>\n",
       "      <td>baekbeans</td>\n",
       "      <td>34599</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'Overall': '10', 'Story': '10', 'Animation': ...</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=259117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253664</td>\n",
       "      <td>skrn</td>\n",
       "      <td>28891</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'Overall': '7', 'Story': '7', 'Animation': '9...</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=253664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8254</td>\n",
       "      <td>edgewalker00</td>\n",
       "      <td>2904</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>9</td>\n",
       "      <td>{'Overall': '9', 'Story': '9', 'Animation': '9...</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=8254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291149</td>\n",
       "      <td>aManOfCulture99</td>\n",
       "      <td>4181</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'Overall': '10', 'Story': '10', 'Animation': ...</td>\n",
       "      <td>https://myanimelist.net/reviews.php?id=291149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid          profile  anime_uid  \\\n",
       "0  255938   DesolatePsyche      34096   \n",
       "1  259117        baekbeans      34599   \n",
       "2  253664             skrn      28891   \n",
       "3    8254     edgewalker00       2904   \n",
       "4  291149  aManOfCulture99       4181   \n",
       "\n",
       "                                                text  score  \\\n",
       "0  \\n           \\n         \\n           \\n       ...      8   \n",
       "1  \\n           \\n         \\n           \\n       ...     10   \n",
       "2  \\n           \\n         \\n           \\n       ...      7   \n",
       "3  \\n           \\n         \\n           \\n       ...      9   \n",
       "4  \\n           \\n         \\n           \\n       ...     10   \n",
       "\n",
       "                                              scores  \\\n",
       "0  {'Overall': '8', 'Story': '8', 'Animation': '8...   \n",
       "1  {'Overall': '10', 'Story': '10', 'Animation': ...   \n",
       "2  {'Overall': '7', 'Story': '7', 'Animation': '9...   \n",
       "3  {'Overall': '9', 'Story': '9', 'Animation': '9...   \n",
       "4  {'Overall': '10', 'Story': '10', 'Animation': ...   \n",
       "\n",
       "                                            link  \n",
       "0  https://myanimelist.net/reviews.php?id=255938  \n",
       "1  https://myanimelist.net/reviews.php?id=259117  \n",
       "2  https://myanimelist.net/reviews.php?id=253664  \n",
       "3    https://myanimelist.net/reviews.php?id=8254  \n",
       "4  https://myanimelist.net/reviews.php?id=291149  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d785c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of animes with a review : 8113\n",
      "Total number of reviews : 130519\n",
      "Average number of reviews per reviewed anime : 16.08763712560089\n"
     ]
    }
   ],
   "source": [
    "reviewed_animes = df_reviews['anime_uid'].nunique()\n",
    "print(f'Number of animes with a review : {reviewed_animes}')\n",
    "print(f'Total number of reviews : {len(df_reviews)}')\n",
    "print(f'Average number of reviews per reviewed anime : {len(df_reviews)/reviewed_animes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67436b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_reviews = df_reviews.groupby('anime_uid', as_index=False).agg({'text':' '.join})\n",
    "#pd.reset_option('display.max_colwidth', None)\n",
    "#concat_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc96dd9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concat_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m sao_id = \u001b[32m11757\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m reviews_sao = \u001b[43mconcat_reviews\u001b[49m[concat_reviews[\u001b[33m'\u001b[39m\u001b[33manime_uid\u001b[39m\u001b[33m'\u001b[39m] == sao_id][\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(reviews_sao.apply(\u001b[38;5;28mlen\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'concat_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "sao_id = 11757\n",
    "\n",
    "reviews_sao = concat_reviews[concat_reviews['anime_uid'] == sao_id]['text']\n",
    "print(reviews_sao.apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ef2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def lemmatize_text(text):\n",
    "#    doc = nlp(text)\n",
    "#    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "#nlp.max_length = 1500000\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"[\\n\\r]\", \" \", text)\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95514b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_reviews[\"cleaned_text\"] = concat_reviews['text'].apply(clean_text)\n",
    "\n",
    "#cleaned_texts = []\n",
    "\n",
    "#for i, text in enumerate(concat_reviews['text']):\n",
    "#    cleaned_text = clean_text(text)\n",
    "#    cleaned_texts.append(cleaned_text)\n",
    "#    print(f\"Progress: {i + 1}/{len(concat_reviews)}\")\n",
    "\n",
    "#concat_reviews['cleaned_text'] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5040b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "591b0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_texts = []\n",
    "\n",
    "#for i, text in enumerate(df_reviews['text']):\n",
    "#    cleaned_text = clean_and_split_text(text)\n",
    "#    print(f\"Progress: {i + 1}/{len(df_reviews)}\")\n",
    "\n",
    "#df_reviews['chunked_text'] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae96b303",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<unknown>, line 9)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3670\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[10]\u001b[39m\u001b[92m, line 2\u001b[39m\n    reviews_for_llm['text'] = reviews_for_llm[\"text\"].apply(ast.literal_eval)\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m in \u001b[95mapply\u001b[39m\n    ).apply()\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m in \u001b[95mapply\u001b[39m\n    return self.apply_standard()\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m in \u001b[95mapply_standard\u001b[39m\n    mapped = obj._map_values(\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m in \u001b[95m_map_values\u001b[39m\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m in \u001b[95mmap_array\u001b[39m\n    return lib.map_infer(values, mapper, convert=convert)\n",
      "  File \u001b[92mlib.pyx:2972\u001b[39m in \u001b[95mpandas._libs.lib.map_infer\u001b[39m\n",
      "  File \u001b[92m/usr/lib/python3.12/ast.py:66\u001b[39m in \u001b[95mliteral_eval\u001b[39m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ast.py:52\u001b[39m\u001b[36m in \u001b[39m\u001b[35mparse\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn compile(source, filename, mode, flags,\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<unknown>:9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmore pics\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "reviews_for_llm = df_reviews.drop(columns=[\"uid\",\"profile\",\"score\",\"scores\",\"link\"])\n",
    "reviews_for_llm['text'] = reviews_for_llm[\"text\"].apply(ast.literal_eval)\n",
    "reviews_for_llm['text'].progress_apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f1d9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.to_csv('cleaned_and_split_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06d191ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' more pics Overall Story Animation Sound Character Enjoyment First things first My reviews system is explained on a blog entry Which can be found through my profile I m going to keep this review more of a opinion of Gintama s overall and then this season specific Anyhow What I have always loved regarding Gintama is its content of everything I love the comedy its absurd random can be vile dirty sweet anyhow everything Have laughed countless times in this franchise Also the humor they have also is heavily ref',\n",
       " 'erence based a k a parodies of different anime shows manga live stuff real world anime production and so on Anyhow comedy parody side of this franchise i absolutely love Now nd side of this show is the serious dramas epic battle shounens and so on There are arcs that are fully comedy arcs that are fully serious and mixtures of both Serious side is usually quite dramatic and managed to somewhat tear me up now and then Whilst the action sequences are absolute bliss as well They are just presented in a really ',\n",
       " 'cool manner And extra points when sometime the add artistic element Of course it has its slice of life side and pseudo romance Those are weaker side but ain t the focus But when sometimes those are the focus then they are done in enjoyable method To sum up overall gintama s I love the serious side and the silly side Art and sound voice acting ost op ed is something I loved in all gintamas across the board They just click with me bliss to look at bliss to hear Music op ed specifically are hyped up and upbeat',\n",
       " ' which generally I don t like but gintama is the exception where I love them Art is cool sometimes artistic sometimes simple It has a bit of everything that makes it enjoyable And gore is absolutely satisfying as well well the blood to be specific Well the serious side of stories in this anime are superb in my opinion or the overall idea of story that moves now and then But wouldn t say comedic side of series story is any worse When at times comedy side has story It s usually quite enjoyable Regarding chara',\n",
       " 'cters I don t have much to say other than that variety stereotypes of off stereotypes is very large As well characters with depth but as well with oddity is as well in great selection Main team Gintoki the lazy dirty slob with superb second side of seriousness and caring about friends allies Shinpachi the poor straight man act sidekick who adds great value to the team Kagura the battle race girl that doesn t act like girl almost at all or in another words a dirty slob girl in a sense Now to this season spec',\n",
       " 'ific I found it a bit disappointing Mainly because usually in gintama we have overly serious arcs or fully comedic whilst this one had a bit of mixture of both which somewhat ruined the experience Plus the artistic presentation felt this time around a bit lacking Maybe because of another studio who knows But anyhow it didn t feel as superb Rather than gintama it felt as watching just another good battle shounen anime in modern day with simplified animation I mean it definitely was not any bad just didn t ha',\n",
       " 've the punch Gintama usually has Might be because it was short series maybe because it focused too much moving on with story It ll be shame to see it finalized in this manner Rest I pretty much loved as usual in Gintama franchise Helpful ']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class['chunked_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "261104da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:06<00:00,  8.36it/s]\n",
      "/tmp/ipykernel_85088/3745356283.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_class.loc[:,\"classifications\"] = df_class[\"chunked_text\"].loc[:50].progress_apply(pipe_sentiment)\n"
     ]
    }
   ],
   "source": [
    "df_class.loc[:,\"classifications\"] = df_class[\"chunked_text\"].loc[:50].progress_apply(pipe_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e32a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4002/130519 [11:18<5:57:26,  5.90it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_class.loc[:,\u001b[33m\"\u001b[39m\u001b[33mclassifications\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf_class\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunked_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe_sentiment\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/tqdm/std.py:917\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    919\u001b[39m     t.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/tqdm/std.py:912\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    907\u001b[39m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[32m    908\u001b[39m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[32m    911\u001b[39m     t.update(n=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.total \u001b[38;5;129;01mor\u001b[39;00m t.n < t.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:159\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m inputs = (inputs,)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    161\u001b[39m _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/pipelines/base.py:1412\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1409\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1410\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1411\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:19\u001b[39m, in \u001b[36mPipelineDataset.__getitem__\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[32m     18\u001b[39m     item = \u001b[38;5;28mself\u001b[39m.dataset[i]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:183\u001b[39m, in \u001b[36mTextClassificationPipeline.preprocess\u001b[39m\u001b[34m(self, inputs, **tokenizer_kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# This is likely an invalid usage of the pipeline attempting to pass text pairs.\u001b[39;00m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe pipeline received invalid inputs, if you are trying to send text pairs, you can try to send a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m dictionary `\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMy text\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtext_pair\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMy pair\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}` in order to send a text pair.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2867\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2865\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2866\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2867\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2868\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2869\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2977\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_encode_plus(\n\u001b[32m   2956\u001b[39m         batch_text_or_text_pairs=batch_text_or_text_pairs,\n\u001b[32m   2957\u001b[39m         add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2974\u001b[39m         **kwargs,\n\u001b[32m   2975\u001b[39m     )\n\u001b[32m   2976\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2977\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2980\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2990\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2996\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2997\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2998\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3052\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3024\u001b[39m \u001b[33;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[32m   3025\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3040\u001b[39m \u001b[33;03m        method).\u001b[39;00m\n\u001b[32m   3041\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3043\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3044\u001b[39m     padding=padding,\n\u001b[32m   3045\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3049\u001b[39m     **kwargs,\n\u001b[32m   3050\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3052\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msplit_special_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:615\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_encode_plus\u001b[39m(\n\u001b[32m    592\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    593\u001b[39m     text: Union[TextInput, PreTokenizedInput],\n\u001b[32m   (...)\u001b[39m\u001b[32m    612\u001b[39m     **kwargs,\n\u001b[32m    613\u001b[39m ) -> BatchEncoding:\n\u001b[32m    614\u001b[39m     batched_input = [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     batched_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[32m    638\u001b[39m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:541\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tokenizer.encode_special_tokens != split_special_tokens:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28mself\u001b[39m._tokenizer.encode_special_tokens = split_special_tokens\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[32m    553\u001b[39m tokens_and_encodings = [\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m._convert_encoding(\n\u001b[32m    555\u001b[39m         encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    564\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[32m    565\u001b[39m ]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_class.loc[:,\"classifications\"] = df_class[\"chunked_text\"].progress_apply(pipe_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "372040a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9992042183876038},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996769428253174},\n",
       " {'label': 'NEGATIVE', 'score': 0.7189896106719971},\n",
       " {'label': 'POSITIVE', 'score': 0.5227293968200684},\n",
       " {'label': 'POSITIVE', 'score': 0.9850171804428101},\n",
       " {'label': 'NEGATIVE', 'score': 0.9953349232673645},\n",
       " {'label': 'POSITIVE', 'score': 0.9966551065444946},\n",
       " {'label': 'POSITIVE', 'score': 0.9956899285316467},\n",
       " {'label': 'NEGATIVE', 'score': 0.9622377753257751},\n",
       " {'label': 'NEGATIVE', 'score': 0.9748064279556274},\n",
       " {'label': 'POSITIVE', 'score': 0.987274169921875},\n",
       " {'label': 'POSITIVE', 'score': 0.8943804502487183}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class[\"classifications\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abed87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_score(classifications):\n",
    "    if isinstance(classifications, list):\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for item in classifications:\n",
    "            score = item['score']\n",
    "            if item['label'] == 'NEGATIVE':\n",
    "                score = -score\n",
    "            total += score\n",
    "            count += 1\n",
    "        return total / count if count else 0\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5be40a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85088/1758409613.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_class.loc[:,'mean_score'] = df_class['classifications'].apply(calculate_mean_score)\n"
     ]
    }
   ],
   "source": [
    "df_class.loc[:,'mean_score'] = df_class['classifications'].apply(calculate_mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2dc9910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.424159\n",
       "1     0.797101\n",
       "2     0.332255\n",
       "3    -0.022375\n",
       "4     0.506765\n",
       "5     0.996296\n",
       "6    -0.059540\n",
       "7     0.401125\n",
       "8     0.119885\n",
       "9    -0.485066\n",
       "10   -0.985845\n",
       "Name: mean_score, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class['mean_score'].loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d52ee938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sentiment(score):\n",
    "    if 0.2 <= score <= 1:\n",
    "        return \"POSITIVE\"\n",
    "    elif -0.2 <= score < 0.2:\n",
    "        return \"MIXED FEELINGS\"\n",
    "    else:\n",
    "        return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37de4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[:,'gen_classification'] = df_class['mean_score'].apply(determine_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d90263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           POSITIVE\n",
       "1           POSITIVE\n",
       "2           POSITIVE\n",
       "3     MIXED FEELINGS\n",
       "4           POSITIVE\n",
       "5           POSITIVE\n",
       "6     MIXED FEELINGS\n",
       "7           POSITIVE\n",
       "8     MIXED FEELINGS\n",
       "9           NEGATIVE\n",
       "10          NEGATIVE\n",
       "Name: gen_classification, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class['gen_classification'].loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42aa94b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>anime_uid</th>\n",
       "      <th>text</th>\n",
       "      <th>chunked_text</th>\n",
       "      <th>classifications</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>gen_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DesolatePsyche</td>\n",
       "      <td>34096</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.969215750694...</td>\n",
       "      <td>0.424159</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baekbeans</td>\n",
       "      <td>34599</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.953255474567...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skrn</td>\n",
       "      <td>28891</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.994730710983...</td>\n",
       "      <td>0.332255</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edgewalker00</td>\n",
       "      <td>2904</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999204218387...</td>\n",
       "      <td>-0.022375</td>\n",
       "      <td>MIXED FEELINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aManOfCulture99</td>\n",
       "      <td>4181</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.997363150119...</td>\n",
       "      <td>0.506765</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eneri</td>\n",
       "      <td>2904</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.991586685180...</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Waffle_Empress</td>\n",
       "      <td>16664</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999297976493...</td>\n",
       "      <td>-0.059540</td>\n",
       "      <td>MIXED FEELINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NIGGER_BONER</td>\n",
       "      <td>2904</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.995272338390...</td>\n",
       "      <td>0.401125</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jchang</td>\n",
       "      <td>2904</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.998441040515...</td>\n",
       "      <td>0.119885</td>\n",
       "      <td>MIXED FEELINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shadowsplat</td>\n",
       "      <td>4181</td>\n",
       "      <td>\\n           \\n         \\n           \\n       ...</td>\n",
       "      <td>[ more pics Overall Story Animation Sound Char...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.531278789043...</td>\n",
       "      <td>-0.485066</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           profile  anime_uid  \\\n",
       "0   DesolatePsyche      34096   \n",
       "1        baekbeans      34599   \n",
       "2             skrn      28891   \n",
       "3     edgewalker00       2904   \n",
       "4  aManOfCulture99       4181   \n",
       "5            eneri       2904   \n",
       "6   Waffle_Empress      16664   \n",
       "7     NIGGER_BONER       2904   \n",
       "8           jchang       2904   \n",
       "9      shadowsplat       4181   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\n           \\n         \\n           \\n       ...   \n",
       "1  \\n           \\n         \\n           \\n       ...   \n",
       "2  \\n           \\n         \\n           \\n       ...   \n",
       "3  \\n           \\n         \\n           \\n       ...   \n",
       "4  \\n           \\n         \\n           \\n       ...   \n",
       "5  \\n           \\n         \\n           \\n       ...   \n",
       "6  \\n           \\n         \\n           \\n       ...   \n",
       "7  \\n           \\n         \\n           \\n       ...   \n",
       "8  \\n           \\n         \\n           \\n       ...   \n",
       "9  \\n           \\n         \\n           \\n       ...   \n",
       "\n",
       "                                        chunked_text  \\\n",
       "0  [ more pics Overall Story Animation Sound Char...   \n",
       "1  [ more pics Overall Story Animation Sound Char...   \n",
       "2  [ more pics Overall Story Animation Sound Char...   \n",
       "3  [ more pics Overall Story Animation Sound Char...   \n",
       "4  [ more pics Overall Story Animation Sound Char...   \n",
       "5  [ more pics Overall Story Animation Sound Char...   \n",
       "6  [ more pics Overall Story Animation Sound Char...   \n",
       "7  [ more pics Overall Story Animation Sound Char...   \n",
       "8  [ more pics Overall Story Animation Sound Char...   \n",
       "9  [ more pics Overall Story Animation Sound Char...   \n",
       "\n",
       "                                     classifications  mean_score  \\\n",
       "0  [{'label': 'POSITIVE', 'score': 0.969215750694...    0.424159   \n",
       "1  [{'label': 'POSITIVE', 'score': 0.953255474567...    0.797101   \n",
       "2  [{'label': 'POSITIVE', 'score': 0.994730710983...    0.332255   \n",
       "3  [{'label': 'NEGATIVE', 'score': 0.999204218387...   -0.022375   \n",
       "4  [{'label': 'POSITIVE', 'score': 0.997363150119...    0.506765   \n",
       "5  [{'label': 'POSITIVE', 'score': 0.991586685180...    0.996296   \n",
       "6  [{'label': 'NEGATIVE', 'score': 0.999297976493...   -0.059540   \n",
       "7  [{'label': 'NEGATIVE', 'score': 0.995272338390...    0.401125   \n",
       "8  [{'label': 'POSITIVE', 'score': 0.998441040515...    0.119885   \n",
       "9  [{'label': 'POSITIVE', 'score': 0.531278789043...   -0.485066   \n",
       "\n",
       "  gen_classification  \n",
       "0           POSITIVE  \n",
       "1           POSITIVE  \n",
       "2           POSITIVE  \n",
       "3     MIXED FEELINGS  \n",
       "4           POSITIVE  \n",
       "5           POSITIVE  \n",
       "6     MIXED FEELINGS  \n",
       "7           POSITIVE  \n",
       "8     MIXED FEELINGS  \n",
       "9           NEGATIVE  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1671e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.drop[['chunked_text', 'profile', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.to_csv('classed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad335d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_2 = pd.read_csv('/home/antog96/Jedha_Bootcamp/Projet_DSFS/anime-recommendation-engine/data/reviews_classed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ec1f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>anime_uid</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>classifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DesolatePsyche</td>\n",
       "      <td>34096</td>\n",
       "      <td>[' more pics Overall 8 Story 8 Animation 8 Sou...</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.931263029575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baekbeans</td>\n",
       "      <td>34599</td>\n",
       "      <td>[' more pics Overall 10 Story 10 Animation 10 ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.882984995841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skrn</td>\n",
       "      <td>28891</td>\n",
       "      <td>[' more pics Overall 7 Story 7 Animation 9 Sou...</td>\n",
       "      <td>7</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.972522079944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edgewalker00</td>\n",
       "      <td>2904</td>\n",
       "      <td>[' more pics Overall 9 Story 9 Animation 9 Sou...</td>\n",
       "      <td>9</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999156832695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aManOfCulture99</td>\n",
       "      <td>4181</td>\n",
       "      <td>[' more pics Overall 10 Story 10 Animation 8 S...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.998817861080...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           profile  anime_uid  \\\n",
       "0   DesolatePsyche      34096   \n",
       "1        baekbeans      34599   \n",
       "2             skrn      28891   \n",
       "3     edgewalker00       2904   \n",
       "4  aManOfCulture99       4181   \n",
       "\n",
       "                                                text  score  \\\n",
       "0  [' more pics Overall 8 Story 8 Animation 8 Sou...      8   \n",
       "1  [' more pics Overall 10 Story 10 Animation 10 ...     10   \n",
       "2  [' more pics Overall 7 Story 7 Animation 9 Sou...      7   \n",
       "3  [' more pics Overall 9 Story 9 Animation 9 Sou...      9   \n",
       "4  [' more pics Overall 10 Story 10 Animation 8 S...     10   \n",
       "\n",
       "                                     classifications  \n",
       "0  [{'label': 'POSITIVE', 'score': 0.931263029575...  \n",
       "1  [{'label': 'POSITIVE', 'score': 0.882984995841...  \n",
       "2  [{'label': 'POSITIVE', 'score': 0.972522079944...  \n",
       "3  [{'label': 'NEGATIVE', 'score': 0.999156832695...  \n",
       "4  [{'label': 'POSITIVE', 'score': 0.998817861080...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82447f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_2[\"classifications\"] = df_class_2[\"classifications\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c482c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_score(classifications):\n",
    "    if isinstance(classifications, list):\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for item in classifications:\n",
    "            score = item['score']\n",
    "            if item['label'] == 'NEGATIVE':\n",
    "                score = -score\n",
    "            total += score\n",
    "            count += 1\n",
    "        return total / count if count else 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f45df5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130519/130519 [00:00<00:00, 473757.17it/s]\n"
     ]
    }
   ],
   "source": [
    "df_class_2.loc[:,'mean_score'] = df_class_2['classifications'].progress_apply(calculate_mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9581219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sentiment(score):\n",
    "    if 0.2 <= score <= 1:\n",
    "        return \"POSITIVE\"\n",
    "    elif -0.2 <= score < 0.2:\n",
    "        return \"MIXED FEELINGS\"\n",
    "    else:\n",
    "        return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d1f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130519/130519 [00:00<00:00, 1054156.97it/s]\n"
     ]
    }
   ],
   "source": [
    "df_class_2.loc[:,'gen_classification'] = df_class_2['mean_score'].progress_apply(determine_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df53d56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>anime_uid</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>classifications</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>gen_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DesolatePsyche</td>\n",
       "      <td>34096</td>\n",
       "      <td>[' more pics Overall 8 Story 8 Animation 8 Sou...</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.931263029575...</td>\n",
       "      <td>0.418560</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baekbeans</td>\n",
       "      <td>34599</td>\n",
       "      <td>[' more pics Overall 10 Story 10 Animation 10 ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.882984995841...</td>\n",
       "      <td>0.573358</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skrn</td>\n",
       "      <td>28891</td>\n",
       "      <td>[' more pics Overall 7 Story 7 Animation 9 Sou...</td>\n",
       "      <td>7</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.972522079944...</td>\n",
       "      <td>0.306899</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edgewalker00</td>\n",
       "      <td>2904</td>\n",
       "      <td>[' more pics Overall 9 Story 9 Animation 9 Sou...</td>\n",
       "      <td>9</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999156832695...</td>\n",
       "      <td>0.119605</td>\n",
       "      <td>MIXED FEELINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aManOfCulture99</td>\n",
       "      <td>4181</td>\n",
       "      <td>[' more pics Overall 10 Story 10 Animation 8 S...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.998817861080...</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           profile  anime_uid  \\\n",
       "0   DesolatePsyche      34096   \n",
       "1        baekbeans      34599   \n",
       "2             skrn      28891   \n",
       "3     edgewalker00       2904   \n",
       "4  aManOfCulture99       4181   \n",
       "\n",
       "                                                text  score  \\\n",
       "0  [' more pics Overall 8 Story 8 Animation 8 Sou...      8   \n",
       "1  [' more pics Overall 10 Story 10 Animation 10 ...     10   \n",
       "2  [' more pics Overall 7 Story 7 Animation 9 Sou...      7   \n",
       "3  [' more pics Overall 9 Story 9 Animation 9 Sou...      9   \n",
       "4  [' more pics Overall 10 Story 10 Animation 8 S...     10   \n",
       "\n",
       "                                     classifications  mean_score  \\\n",
       "0  [{'label': 'POSITIVE', 'score': 0.931263029575...    0.418560   \n",
       "1  [{'label': 'POSITIVE', 'score': 0.882984995841...    0.573358   \n",
       "2  [{'label': 'POSITIVE', 'score': 0.972522079944...    0.306899   \n",
       "3  [{'label': 'NEGATIVE', 'score': 0.999156832695...    0.119605   \n",
       "4  [{'label': 'POSITIVE', 'score': 0.998817861080...    0.500251   \n",
       "\n",
       "  gen_classification  \n",
       "0           POSITIVE  \n",
       "1           POSITIVE  \n",
       "2           POSITIVE  \n",
       "3     MIXED FEELINGS  \n",
       "4           POSITIVE  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d18c09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_reviews = df_class_2[df_class_2[\"gen_classification\"] == \"NEGATIVE\"]\n",
    "df_positive_reviews = df_class_2[df_class_2[\"gen_classification\"] == \"POSITIVE\"]\n",
    "df_mixedfeelings_reviews = df_class_2[df_class_2[\"gen_classification\"] == \"MIXED FEELINGS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224e1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_reviews.to_csv('df_negative_reviews.csv')\n",
    "df_positive_reviews.to_csv('df_positive_reviews.csv')\n",
    "df_mixedfeelings_reviews.to_csv('df_mixedfeelings_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd54170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42270, 7)\n",
      "(62314, 7)\n",
      "(25935, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_negative_reviews.shape)\n",
    "print(df_positive_reviews.shape)\n",
    "print(df_mixedfeelings_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c9988ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8113\n",
      "Animes with negative reviews : 5799\n",
      "Animes with positive reviews : 5920\n",
      "Animes with mixed reviews : 4678\n"
     ]
    }
   ],
   "source": [
    "print(df_class_2['anime_uid'].nunique())\n",
    "print(f'Animes with negative reviews : {df_negative_reviews['anime_uid'].nunique()}')\n",
    "print(f'Animes with positive reviews : {df_positive_reviews['anime_uid'].nunique()}')\n",
    "print(f'Animes with mixed reviews : {df_mixedfeelings_reviews['anime_uid'].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4689f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_with_neg_reviews = set(df_negative_reviews['anime_uid'].unique())\n",
    "animes_with_pos_reviews = set(df_positive_reviews['anime_uid'].unique())\n",
    "animes_with_mixed_reviews = set(df_mixedfeelings_reviews['anime_uid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e0db29d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animes_only_in_mixed = (animes_with_mixed_reviews - animes_with_neg_reviews) - animes_with_pos_reviews\n",
    "len(animes_only_in_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e5bd3267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animes_only_in_neg = (animes_with_neg_reviews - animes_with_pos_reviews) - animes_with_mixed_reviews\n",
    "len(animes_only_in_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1123e03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animes_only_in_pos = (animes_with_pos_reviews - animes_with_neg_reviews) - animes_with_mixed_reviews\n",
    "len(animes_only_in_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d58b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unchunk_text(text):\n",
    "    fused_text = \"\"\n",
    "    for chunk in text:\n",
    "        fused_text += chunk\n",
    "    return fused_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d41b5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1053/991039155.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_negative_reviews['text'] = df_negative_reviews['text'].apply(ast.literal_eval)\n",
      "/tmp/ipykernel_1053/991039155.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_positive_reviews['text'] = df_positive_reviews['text'].apply(ast.literal_eval)\n",
      "/tmp/ipykernel_1053/991039155.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mixedfeelings_reviews['text'] = df_mixedfeelings_reviews['text'].apply(ast.literal_eval)\n"
     ]
    }
   ],
   "source": [
    "df_negative_reviews['text'] = df_negative_reviews['text'].apply(ast.literal_eval)\n",
    "df_positive_reviews['text'] = df_positive_reviews['text'].apply(ast.literal_eval)\n",
    "df_mixedfeelings_reviews['text'] = df_mixedfeelings_reviews['text'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a48c4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1053/2633916163.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_negative_reviews['text'] = df_negative_reviews['text'].apply(unchunk_text)\n",
      "/tmp/ipykernel_1053/2633916163.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_positive_reviews['text'] = df_positive_reviews['text'].apply(unchunk_text)\n",
      "/tmp/ipykernel_1053/2633916163.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mixedfeelings_reviews['text'] = df_mixedfeelings_reviews['text'].apply(unchunk_text)\n"
     ]
    }
   ],
   "source": [
    "df_negative_reviews['text'] = df_negative_reviews['text'].apply(unchunk_text)\n",
    "df_positive_reviews['text'] = df_positive_reviews['text'].apply(unchunk_text)\n",
    "df_mixedfeelings_reviews['text'] = df_mixedfeelings_reviews['text'].apply(unchunk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d76457fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_for_summary(text):    \n",
    "    text_splited = re.findall('.{1024}', text)\n",
    "    text_splited.append(text[1024 * len(text_splited):])\n",
    "    return text_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "212bd8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42270/42270 [00:00<00:00, 232760.84it/s]\n",
      "/tmp/ipykernel_1053/3806439965.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_negative_reviews.loc[:,'chunked_text'] = df_negative_reviews.loc[:,\"text\"].progress_apply(split_text_for_summary)\n",
      "100%|██████████| 62314/62314 [00:00<00:00, 204367.58it/s]\n",
      "/tmp/ipykernel_1053/3806439965.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_positive_reviews.loc[:,'chunked_text'] = df_positive_reviews.loc[:,\"text\"].progress_apply(split_text_for_summary)\n",
      "100%|██████████| 25935/25935 [00:00<00:00, 141293.44it/s]\n",
      "/tmp/ipykernel_1053/3806439965.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mixedfeelings_reviews.loc[:,'chunked_text'] = df_mixedfeelings_reviews.loc[:,\"text\"].progress_apply(split_text_for_summary)\n"
     ]
    }
   ],
   "source": [
    "df_negative_reviews.loc[:,'chunked_text'] = df_negative_reviews.loc[:,\"text\"].progress_apply(split_text_for_summary)\n",
    "df_positive_reviews.loc[:,'chunked_text'] = df_positive_reviews.loc[:,\"text\"].progress_apply(split_text_for_summary)\n",
    "df_mixedfeelings_reviews.loc[:,'chunked_text'] = df_mixedfeelings_reviews.loc[:,\"text\"].progress_apply(split_text_for_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a49a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>anime_uid</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>classifications</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>gen_classification</th>\n",
       "      <th>chunked_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Waffle_Empress</td>\n",
       "      <td>16664</td>\n",
       "      <td>more pics Overall 6 Story 6 Animation 9 Sound...</td>\n",
       "      <td>6</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999612748622...</td>\n",
       "      <td>-0.672079</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 6 Story 6 Animation 9 Soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shadowsplat</td>\n",
       "      <td>4181</td>\n",
       "      <td>more pics Overall 4 Story 8 Animation 9 Sound...</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.621118187904...</td>\n",
       "      <td>-0.458163</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 4 Story 8 Animation 9 Soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>angelsreview</td>\n",
       "      <td>4672</td>\n",
       "      <td>more pics Overall 8 Story 6 Animation 7 Sound...</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999028086662...</td>\n",
       "      <td>-0.385837</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 8 Story 6 Animation 7 Soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rigas</td>\n",
       "      <td>4181</td>\n",
       "      <td>more pics Overall 5 Story 4 Animation 7 Sound...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.967860877513...</td>\n",
       "      <td>-0.652592</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 5 Story 4 Animation 7 Soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Leyvon</td>\n",
       "      <td>4181</td>\n",
       "      <td>more pics Overall 10 Story 10 Animation 10 So...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.990030050277...</td>\n",
       "      <td>-0.990030</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 10 Story 10 Animation 10 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SieghartTheMage</td>\n",
       "      <td>1253</td>\n",
       "      <td>more pics Overall 8 Story 8 Animation 8 Sound...</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999048769474...</td>\n",
       "      <td>-0.997749</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 8 Story 8 Animation 8 Soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ggultra2764</td>\n",
       "      <td>1425</td>\n",
       "      <td>more pics Overall 7 Story 7 Animation 6 Sound...</td>\n",
       "      <td>7</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.992316722869...</td>\n",
       "      <td>-0.252149</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 7 Story 7 Animation 6 Soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gwern</td>\n",
       "      <td>7588</td>\n",
       "      <td>more pics Overall 7 Story 7 Animation 6 Sound...</td>\n",
       "      <td>7</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999524593353...</td>\n",
       "      <td>-0.999345</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[ more pics Overall 7 Story 7 Animation 6 Soun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            profile  anime_uid  \\\n",
       "6    Waffle_Empress      16664   \n",
       "9       shadowsplat       4181   \n",
       "10     angelsreview       4672   \n",
       "20            Rigas       4181   \n",
       "24           Leyvon       4181   \n",
       "30  SieghartTheMage       1253   \n",
       "31      ggultra2764       1425   \n",
       "35            gwern       7588   \n",
       "\n",
       "                                                 text  score  \\\n",
       "6    more pics Overall 6 Story 6 Animation 9 Sound...      6   \n",
       "9    more pics Overall 4 Story 8 Animation 9 Sound...      4   \n",
       "10   more pics Overall 8 Story 6 Animation 7 Sound...      8   \n",
       "20   more pics Overall 5 Story 4 Animation 7 Sound...      5   \n",
       "24   more pics Overall 10 Story 10 Animation 10 So...     10   \n",
       "30   more pics Overall 8 Story 8 Animation 8 Sound...      8   \n",
       "31   more pics Overall 7 Story 7 Animation 6 Sound...      7   \n",
       "35   more pics Overall 7 Story 7 Animation 6 Sound...      7   \n",
       "\n",
       "                                      classifications  mean_score  \\\n",
       "6   [{'label': 'NEGATIVE', 'score': 0.999612748622...   -0.672079   \n",
       "9   [{'label': 'POSITIVE', 'score': 0.621118187904...   -0.458163   \n",
       "10  [{'label': 'NEGATIVE', 'score': 0.999028086662...   -0.385837   \n",
       "20  [{'label': 'NEGATIVE', 'score': 0.967860877513...   -0.652592   \n",
       "24  [{'label': 'NEGATIVE', 'score': 0.990030050277...   -0.990030   \n",
       "30  [{'label': 'NEGATIVE', 'score': 0.999048769474...   -0.997749   \n",
       "31  [{'label': 'NEGATIVE', 'score': 0.992316722869...   -0.252149   \n",
       "35  [{'label': 'NEGATIVE', 'score': 0.999524593353...   -0.999345   \n",
       "\n",
       "   gen_classification                                       chunked_text  \n",
       "6            NEGATIVE  [ more pics Overall 6 Story 6 Animation 9 Soun...  \n",
       "9            NEGATIVE  [ more pics Overall 4 Story 8 Animation 9 Soun...  \n",
       "10           NEGATIVE  [ more pics Overall 8 Story 6 Animation 7 Soun...  \n",
       "20           NEGATIVE  [ more pics Overall 5 Story 4 Animation 7 Soun...  \n",
       "24           NEGATIVE  [ more pics Overall 10 Story 10 Animation 10 S...  \n",
       "30           NEGATIVE  [ more pics Overall 8 Story 8 Animation 8 Soun...  \n",
       "31           NEGATIVE  [ more pics Overall 7 Story 7 Animation 6 Soun...  \n",
       "35           NEGATIVE  [ more pics Overall 7 Story 7 Animation 6 Soun...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6    [ more pics Overall 6 Story 6 Animation 9 Sound 8 Character 6 Enjoyment 6 As someone who loves Studio Ghibli and its movies I expected to see something incredible and life changing However this movie was kind of a disappointment as I found it hard to remain attentive or just care for the characters or the plot Story 6 10 I noticed that I am not really interested in adaptations of legends and myths despite my interest in them as well as cultures of many different cultures Japan being one of them It kind of reminds me of Thumbelina to an extent although I am fully aware that the Japanese fairy tale is way older than its counterpart from the 19th century please don t get me wrong It s a story about a mysterious girl so beautiful that even princes were dying to ask for her hand in marriage However Kaguya s destiny has nothing to do with ordinary human life even that of a noble It s slow and overly complicated which normally works in other Ghibli movies but this time these unnecessary complications made this incred, ibly slow movie hard to watch This movie is too long for such a short story Art 9 10 The art style of this movie reminds me of old Japanese engravings I am sure this is the image the animators and artists were trying to create and they did a great job as it fits the atmosphere of the story perfectly I have no complaints about it so let s give this movie s art a 9 it deserves Sound 8 10 Shame on me I forgot what the music in this anime was like so I had to look for it once again And what can I say Joe Hisaishi knows exactly what he s doing Not his best work but he is very talented and I give him credit for that knowing what he is capable of Character 6 10 When you take an ancient simple tale to work with characters may be rather simple sometimes It s not a rule but it is to be expected They were okay but unfortunately I found it very hard to genuinely care for any of them However showing no interest in any of the characters is even worse than disliking them at least you do feel something when you dislike or ev, en hate a character They were fine but that was it Enjoyment 6 10 I have to admit I was bored As much as I love and respect Ghibli and their attempt to turn this story into a decent movie I failed to like it despite having such high hopes at the beginning when I was just starting to watch it Overall I believe I should stick to other movies Ghibli has to offer as I enjoy them much more Maybe this is not my kind of a movie but this is the second Ghibli film the first one being Tales from Earthsea which is not that big of a surprise I am not going to re watch Helpful ]\n",
       "Name: chunked_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_negative_reviews.head(8))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df_negative_reviews.loc[:8,'chunked_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86aa593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:08<00:00, 22.99s/it]\n",
      "/tmp/ipykernel_1053/1117716840.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_negative_reviews.loc[:,\"summaries\"] = df_negative_reviews.loc[:10,'text'].progress_apply(pipe_summarization)\n"
     ]
    }
   ],
   "source": [
    "df_negative_reviews.loc[:,\"summaries\"] = pipe_summarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d59859d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_text(element):\n",
    "    if isinstance(element, dict):\n",
    "        return element.get('summary_text', '')\n",
    "    elif isinstance(element, list):\n",
    "        # Si c'est une liste, essayez de prendre le premier élément ou une chaîne vide\n",
    "        return element[0].get('summary_text', '') if element and isinstance(element[0], dict) else ''\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b2d53e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1053/536896796.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_negative_reviews['summary'] = df_negative_reviews['summaries'].apply(extract_summary_text)\n"
     ]
    }
   ],
   "source": [
    "df_negative_reviews['summary'] = df_negative_reviews['summaries'].apply(extract_summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38812125",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3670\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[89]\u001b[39m\u001b[92m, line 1\u001b[39m\n    df_negative_reviews = df_negative_reviews[\"summary\"].apply(ast.literal_eval)\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m in \u001b[95mapply\u001b[39m\n    ).apply()\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m in \u001b[95mapply\u001b[39m\n    return self.apply_standard()\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m in \u001b[95mapply_standard\u001b[39m\n    mapped = obj._map_values(\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m in \u001b[95m_map_values\u001b[39m\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "  File \u001b[92m~/Jedha_Bootcamp/Projet_DSFS/DataScience/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m in \u001b[95mmap_array\u001b[39m\n    return lib.map_infer(values, mapper, convert=convert)\n",
      "  File \u001b[92mlib.pyx:2972\u001b[39m in \u001b[95mpandas._libs.lib.map_infer\u001b[39m\n",
      "  File \u001b[92m/usr/lib/python3.12/ast.py:66\u001b[39m in \u001b[95mliteral_eval\u001b[39m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ast.py:52\u001b[39m\u001b[36m in \u001b[39m\u001b[35mparse\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn compile(source, filename, mode, flags,\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<unknown>:1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mAs someone who loves Studio Ghibli and its movies I expected to see something incredible and life changing However this movie was kind of a disappointment as I found it hard to remain attentive or just care for the characters or the plot. This movie is too long for such a short story Art 9 10 The art style of this movie reminds me of old Japanese engravings I am sure this is the image the animators and artists were trying to create and they did a great job. Sound 8 10 Shame on me I forgot what the music in this anime was like so I had to look for it once again.\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_negative_reviews = df_negative_reviews[\"summary\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1384e711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_negative_reviews.loc[:8,'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deef5137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-uncased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e72f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = \"this is a text for test 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daabebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8598906397819519, 'start': 19, 'end': 25, 'answer': 'test 1'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(question=\"What are the positive and negative points expressed in the context text ?\", context=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b04a2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|██████████| 3/3 [02:13<00:00, 44.36s/it] \n",
      "Loading checkpoint shards:  33%|███▎      | 1/3 [00:10<00:20, 10.10s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mistral = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6348ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ea836",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "686712bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m messages = [\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRead the summary of the reviews in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmessage\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and extract the 2 most important drawbacks expressed\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m      3\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'message' is not defined"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f'Read the summary of the reviews in {message} and extract the 2 most important drawbacks expressed'}\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
